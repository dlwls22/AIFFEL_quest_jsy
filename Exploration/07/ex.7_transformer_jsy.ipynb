{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d019892f",
   "metadata": {},
   "source": [
    "# 0. 버전확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ced5c977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3261a5",
   "metadata": {},
   "source": [
    "# Step 1. 데이터 수집하기\n",
    "### 한국어 챗봇 데이터는 송영숙님이 공개한 챗봇 데이터를 사용합니다.\n",
    "\n",
    "Cloud shell에서 아래 명령어를 입력해 주세요.\n",
    "\n",
    "$ mkdir -p ~/aiffel/transformer_chatbot/data/\n",
    "$ ln -s ~/data/* ~/aiffel/transformer_chatbot/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a88c5a",
   "metadata": {},
   "source": [
    "# Step 2. 데이터 전처리하기\n",
    "### 영어 데이터와는 전혀 다른 데이터인 만큼 영어 데이터에 사용했던 전처리와 일부 동일한 전처리도 필요하겠지만 전체적으로는 다른 전처리를 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16210deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfb012c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.expanduser(\"~/aiffel/transformer_chatbot/data/ChatbotData .csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c33084fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 개수: 11823\n"
     ]
    }
   ],
   "source": [
    "num_samples = len(data)\n",
    "print(\"샘플 개수:\", num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e10cad7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n",
    "# A열의 2, 3행이 \"여행은 언제나 좋죠.\" 로 중복값인 것을 확인함. 각 열의 중복값과 누락값을 확인하고자함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c76eb80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q 열의 누락값 개수: 0\n",
      "A 열의 누락값 개수: 0\n"
     ]
    }
   ],
   "source": [
    "# Q열과 A열 각각의 누락값 개수 확인\n",
    "q_missing = data['Q'].isnull().sum()\n",
    "a_missing = data['A'].isnull().sum()\n",
    "\n",
    "print(\"Q 열의 누락값 개수:\", q_missing)\n",
    "print(\"A 열의 누락값 개수:\", a_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69ad8076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q 열의 중복값 개수: 161\n",
      "A 열의 중복값 개수: 4044\n"
     ]
    }
   ],
   "source": [
    "# Q열과 A열 각각의 중복값 개수 확인\n",
    "q_duplicates = data['Q'].duplicated().sum()\n",
    "a_duplicates = data['A'].duplicated().sum()\n",
    "\n",
    "print(\"Q 열의 중복값 개수:\", q_duplicates)\n",
    "print(\"A 열의 중복값 개수:\", a_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73a3e940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복값을 갖는 Q 열 데이터:\n",
      "                             Q                        A  label\n",
      "152    결혼이나 하지 왜 자꾸 나한테 화 내냐구!                   힘들겠네요.      0\n",
      "189             고백하고 후회하면 어떡하지  후회는 후회를 낳을뿐이에요. 용기 내세요.      0\n",
      "195                 고양이 키우고 싶어             자신을 먼저 키우세요.      0\n",
      "196                 고양이 키우고 싶어             가족들과 상의해보세요.      0\n",
      "226          공부는 내 체질이 아닌 것 같아                확신이 없나봐요.      0\n",
      "...                        ...                      ...    ...\n",
      "11658                  첫사랑 생각나           지금의 사랑에 충실하세요.      2\n",
      "11731    커플여행이 나을까 그냥 우리끼리 갈까?         저는 둘이 가는 걸 좋아해요.      2\n",
      "11732    커플여행이 나을까 그냥 우리끼리 갈까?          저는 둘이 가는 게 좋아요.      2\n",
      "11818           훔쳐보는 것도 눈치 보임.       티가 나니까 눈치가 보이는 거죠!      2\n",
      "11819           훔쳐보는 것도 눈치 보임.            훔쳐보는 거 티나나봐요.      2\n",
      "\n",
      "[317 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# 중복값을 갖는 Q열 데이터 확인\n",
    "duplicate_q_data = data[data['Q'].duplicated(keep=False)]\n",
    "\n",
    "print(\"중복값을 갖는 Q 열 데이터:\")\n",
    "print(duplicate_q_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdb0f91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q 열과 A 열이 동시에 중복값을 갖는 데이터 개수: 146\n",
      "중복된 Q와 A 열 데이터:\n",
      "                            Q                        A  label\n",
      "152   결혼이나 하지 왜 자꾸 나한테 화 내냐구!                   힘들겠네요.      0\n",
      "189            고백하고 후회하면 어떡하지  후회는 후회를 낳을뿐이에요. 용기 내세요.      0\n",
      "226         공부는 내 체질이 아닌 것 같아                확신이 없나봐요.      0\n",
      "377                  기숙사 괜찮을까         혼자 사는 것보다 불편하겠죠.      0\n",
      "592                 나는 좋은데 ….           현실의 벽에 부딪혔나봐요.      0\n",
      "...                       ...                      ...    ...\n",
      "8764                   환승 가능?               환승은 30분 안에      1\n",
      "8780          회사 사람들이 아직도 불편해        회사에는 동료가 있을 뿐이에요.      1\n",
      "8782     회사에는 왜 친구 같은 사람이 없을까      회사는 친구 사귀는 곳이 아니에요.      1\n",
      "8789                    후련하달까              후련하니 다행이에요.      1\n",
      "9541             내일 만나자고 해볼까?         멋지게 데이트 신청 해보세요.      2\n",
      "\n",
      "[146 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Q열과 A열이 동시에 중복값을 갖는 데이터 확인\n",
    "duplicate_qa_data = data[data.duplicated(subset=['Q', 'A'], keep=False)]\n",
    "\n",
    "# 중복값의 개수 확인\n",
    "num_duplicates = duplicate_qa_data.shape[0]\n",
    "\n",
    "print(\"Q 열과 A 열이 동시에 중복값을 갖는 데이터 개수:\", num_duplicates)\n",
    "print(\"중복된 Q와 A 열 데이터:\")\n",
    "print(duplicate_qa_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a853e01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152번째 데이터와 중복값을 갖는 데이터의 인덱스: [152, 5527]\n"
     ]
    }
   ],
   "source": [
    "# 152번째 데이터의 Q와 A 값\n",
    "target_q = data.loc[152, 'Q']\n",
    "target_a = data.loc[152, 'A']\n",
    "\n",
    "# 152번째 데이터와 같은 Q와 A 값을 갖는 데이터의 인덱스 찾기\n",
    "duplicate_indices = data[(data['Q'] == target_q) & (data['A'] == target_a)].index.tolist()\n",
    "\n",
    "print(\"152번째 데이터와 중복값을 갖는 데이터의 인덱스:\", duplicate_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48afbb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q        결혼이나 하지 왜 자꾸 나한테 화 내냐구!\n",
      "A                         힘들겠네요.\n",
      "label                          1\n",
      "Name: 5527, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 5527번 데이터 출력\n",
    "print(data.loc[5527])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d891411b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Q            A  label\n",
      "0           12시 땡!   하루가 또 가네요.      0\n",
      "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
      "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
      "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
      "4          PPL 심하네   눈살이 찌푸려지죠.      0\n"
     ]
    }
   ],
   "source": [
    "# Q와 A 열이 동시에 같은 데이터를 하나만 남기고 삭제\n",
    "data = data.drop_duplicates(subset=['Q', 'A'], keep='first').reset_index(drop=True)\n",
    "\n",
    "# 결과 확인\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb1ae99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 개수: 11750\n"
     ]
    }
   ],
   "source": [
    "num_samples = len(data)\n",
    "print(\"샘플 개수:\", num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69128053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Q       Q_filtered            A    A_filtered\n",
      "0           12시 땡!          12시 땡 !   하루가 또 가네요.   하루가 또 가네요 .\n",
      "1      1지망 학교 떨어졌어      1지망 학교 떨어졌어    위로해 드립니다.    위로해 드립니다 .\n",
      "2     3박4일 놀러가고 싶다     3박4일 놀러가고 싶다  여행은 언제나 좋죠.  여행은 언제나 좋죠 .\n",
      "3  3박4일 정도 놀러가고 싶다  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.  여행은 언제나 좋죠 .\n",
      "4          PPL 심하네          PPL 심하네   눈살이 찌푸려지죠.   눈살이 찌푸려지죠 .\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 한글 불용어 목록\n",
    "stopwords = [\n",
    "    \"이\", \"그\", \"저\", \"가\", \"을\", \"를\", \"에\", \"의\", \"와\", \"과\", \"들\"\n",
    "]\n",
    "\n",
    "def preprocess_korean_text(data):\n",
    "    processed_texts = []\n",
    "    \n",
    "    for sentence in data:\n",
    "        # 구두점 처리\n",
    "        sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "        \n",
    "        # 중복 공백 제거\n",
    "        sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "        \n",
    "        # 양쪽 공백 제거\n",
    "        sentence = sentence.strip()\n",
    "        \n",
    "        processed_texts.append(sentence)\n",
    "    \n",
    "    return processed_texts\n",
    "\n",
    "def remove_stopwords(data, stopwords):\n",
    "    filtered_texts = []\n",
    "    \n",
    "    for sentence in data:\n",
    "        # 텍스트를 공백으로 분리하여 단어 리스트 생성\n",
    "        words = sentence.split()\n",
    "        \n",
    "        # 불용어가 아닌 단어만 필터링\n",
    "        filtered_words = [word for word in words if word not in stopwords]\n",
    "        \n",
    "        # 필터링된 단어를 다시 문자열로 결합\n",
    "        filtered_texts.append(' '.join(filtered_words))\n",
    "    \n",
    "    return filtered_texts\n",
    "\n",
    "\n",
    "# Q열과 A열에 각각 전처리 및 불용어 제거 적용\n",
    "data['Q_processed'] = preprocess_korean_text(data['Q'])\n",
    "data['A_processed'] = preprocess_korean_text(data['A'])\n",
    "\n",
    "data['Q_filtered'] = remove_stopwords(data['Q_processed'], stopwords)\n",
    "data['A_filtered'] = remove_stopwords(data['A_processed'], stopwords)\n",
    "\n",
    "# 결과 확인\n",
    "print(data[['Q', 'Q_filtered', 'A', 'A_filtered']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05ed6833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_filtered 열의 개수: 11750\n",
      "A_filtered 열의 개수: 11750\n"
     ]
    }
   ],
   "source": [
    "# Q_filtered와 A_filtered 열의 개수 확인\n",
    "q_filtered_count = data['Q_filtered'].count()\n",
    "a_filtered_count = data['A_filtered'].count()\n",
    "\n",
    "print(\"Q_filtered 열의 개수:\", q_filtered_count)\n",
    "print(\"A_filtered 열의 개수:\", a_filtered_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "249fa206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label       Q_filtered    A_filtered\n",
      "0      0          12시 땡 !   하루가 또 가네요 .\n",
      "1      0      1지망 학교 떨어졌어    위로해 드립니다 .\n",
      "2      0     3박4일 놀러가고 싶다  여행은 언제나 좋죠 .\n",
      "3      0  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠 .\n",
      "4      0          PPL 심하네   눈살이 찌푸려지죠 .\n"
     ]
    }
   ],
   "source": [
    "# Q열과 A열 삭제\n",
    "data = data.drop(columns=['Q', 'A', 'Q_processed', 'A_processed'])\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "088872b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label        questions       answers\n",
      "0      0          12시 땡 !   하루가 또 가네요 .\n",
      "1      0      1지망 학교 떨어졌어    위로해 드립니다 .\n",
      "2      0     3박4일 놀러가고 싶다  여행은 언제나 좋죠 .\n",
      "3      0  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠 .\n",
      "4      0          PPL 심하네   눈살이 찌푸려지죠 .\n"
     ]
    }
   ],
   "source": [
    "# 열 이름 변경\n",
    "data = data.rename(columns={'Q_filtered': 'questions', 'A_filtered': 'answers'})\n",
    "\n",
    "# 결과 확인\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d59df4",
   "metadata": {},
   "source": [
    "# Step 3. SubwordTextEncoder 사용하기\n",
    "### 한국어 데이터는 형태소 분석기를 사용하여 토크나이징을 해야 한다고 많은 분이 알고 있습니다. 하지만 여기서는 형태소 분석기가 아닌 위 실습에서 사용했던 내부 단어 토크나이저인 SubwordTextEncoder를 그대로 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d249f29f",
   "metadata": {},
   "source": [
    "#### 9-4. 트랜스포머의 입력 이해하기_포지셔널 인코딩 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f04aefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fca19e",
   "metadata": {},
   "source": [
    "#### 9-6. 스케일드 닷 프로덕트 어텐션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c071c848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output\n",
    "\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd51471",
   "metadata": {},
   "source": [
    "#### 9-7. 머리가 여러 개인 어텐션_멀티 헤드 어텐션 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5cdcd7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)  # Dense를 적용\n",
    "    key = self.key_dense(key)        # Dense를 적용\n",
    "    value = self.value_dense(value)  # Dense를 적용\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)  # 머리 분리\n",
    "    key = self.split_heads(key, batch_size)        # 머리 분리\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef71b97",
   "metadata": {},
   "source": [
    "#### 9-8. 마스킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c4f4910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b234aadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fc9abb",
   "metadata": {},
   "source": [
    "#### 9-9. 인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77b2ab09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f999dc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637d9a3d",
   "metadata": {},
   "source": [
    "#### 9-10. 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "666dc3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c42b8e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbd7059",
   "metadata": {},
   "source": [
    "#### 1. 단어장(Vocabulary) 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9798ec00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "작업 완료\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# 데이터프레임에서 questions와 answers 열을 리스트로 변환\n",
    "questions = data['questions'].tolist()\n",
    "answers = data['answers'].tolist()\n",
    "\n",
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**14)\n",
    "print(\"작업 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f5568eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "print(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09fb5f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [21851]\n",
      "END_TOKEN의 번호 : [21852]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8357635c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21853\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e6a13b",
   "metadata": {},
   "source": [
    "#### 2. 각 단어를 고유한 정수로 인코딩(Integer encoding) & 패딩(Padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cdfe732f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [5170, 1368, 2601]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [1294, 8659, 6, 6177, 1]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9bf7ad10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문의 최소 길이 : 1\n",
      "질문의 최대 길이 : 16\n",
      "질문의 평균 길이 : 3.925872340425532\n",
      "답변의 최소 길이 : 1\n",
      "답변의 최대 길이 : 23\n",
      "답변의 평균 길이 : 4.702553191489362\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 길이 분포 출력\n",
    "questions_len = [len(s.split()) for s in data['questions']]\n",
    "answers_len = [len(s.split()) for s in data['answers']]\n",
    "\n",
    "print('질문의 최소 길이 : {}'.format(np.min(questions_len)))\n",
    "print('질문의 최대 길이 : {}'.format(np.max(questions_len)))\n",
    "print('질문의 평균 길이 : {}'.format(np.mean(questions_len)))\n",
    "print('답변의 최소 길이 : {}'.format(np.min(answers_len)))\n",
    "print('답변의 최대 길이 : {}'.format(np.max(answers_len)))\n",
    "print('답변의 평균 길이 : {}'.format(np.mean(answers_len)))\n",
    "\n",
    "# 길이 분포 시각화\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.boxplot(questions_len)\n",
    "plt.title('Questions')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(answers_len)\n",
    "plt.title('Answers')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Questions Length Distribution')\n",
    "plt.hist(questions_len, bins=40)\n",
    "plt.xlabel('Length of Samples')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Answers Length Distribution')\n",
    "plt.hist(answers_len, bins=40)\n",
    "plt.xlabel('Length of Samples')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "887bdf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 10\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118bea08",
   "metadata": {},
   "source": [
    "### [실험]\n",
    "### 1. 단어 최대 길이를 길게 해서 모든 데이터를 살리는게 정확도가 높을까?\n",
    "### 2. 단어 최대 길이를 적게 해서 데이터를 소량만 사용하더라도 패딩을 줄이는 것이 더 정확도가 높을까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52aff16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs\n",
    "print(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91976f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 21853\n",
      "필터링 후의 질문 샘플 개수: 11024\n",
      "필터링 후의 답변 샘플 개수: 11024\n"
     ]
    }
   ],
   "source": [
    "# 정수 인코딩 과정을 수행하면서 샘플의 길이가 10을 넘는 경우는 샘플들을 필터링함. 단어장의 크기와 샘플의 개수를 확인\n",
    "import tensorflow as tf\n",
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3bc8146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d126f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "target_vocab_size = 2**14\n",
    "\n",
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=target_vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e53585b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    6648576     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    5775872     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 21853)  5616221     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 18,040,669\n",
      "Trainable params: 18,040,669\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.05 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd4ca224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc221a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ba637a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 된 학습률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ecdd881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7aeab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "da56f728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "26580dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "173/173 [==============================] - 15s 41ms/step - loss: 5.6295 - accuracy: 0.1368\n",
      "Epoch 2/10\n",
      "173/173 [==============================] - 7s 41ms/step - loss: 4.5215 - accuracy: 0.2148\n",
      "Epoch 3/10\n",
      "173/173 [==============================] - 7s 41ms/step - loss: 3.5209 - accuracy: 0.2165\n",
      "Epoch 4/10\n",
      "173/173 [==============================] - 7s 41ms/step - loss: 3.1269 - accuracy: 0.2207\n",
      "Epoch 5/10\n",
      "173/173 [==============================] - 7s 41ms/step - loss: 2.8878 - accuracy: 0.2341\n",
      "Epoch 6/10\n",
      "173/173 [==============================] - 7s 40ms/step - loss: 2.6689 - accuracy: 0.2472\n",
      "Epoch 7/10\n",
      "173/173 [==============================] - 7s 40ms/step - loss: 2.4412 - accuracy: 0.2680\n",
      "Epoch 8/10\n",
      "173/173 [==============================] - 7s 40ms/step - loss: 2.1867 - accuracy: 0.2963\n",
      "Epoch 9/10\n",
      "173/173 [==============================] - 7s 39ms/step - loss: 1.9066 - accuracy: 0.3305\n",
      "Epoch 10/10\n",
      "173/173 [==============================] - 7s 40ms/step - loss: 1.6023 - accuracy: 0.3686\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "history = model.fit(dataset, epochs=EPOCHS, verbose=1)\n",
    "\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "46e9ab50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.629530429840088, 4.521518230438232, 3.520932674407959, 3.1268599033355713, 2.887830972671509, 2.6688735485076904, 2.4411978721618652, 2.18668270111084, 1.906562328338623, 1.602274775505066]\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca93edc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  output = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 예측 시작\n",
    "  for i in range(MAX_LENGTH):\n",
    "    predictions = model(inputs=[sentence, output], training=False)\n",
    "\n",
    "    # 현재(마지막) 시점의 예측 단어를 받아온다.\n",
    "    predictions = predictions[:, -1:, :]\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 마지막 시점의 예측 단어를 출력에 연결한다.\n",
    "    # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0)\n",
    "\n",
    "\n",
    "def predict(sentence):\n",
    "  prediction = evaluate(sentence)\n",
    "\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Output: {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d53f7971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "624dfc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 배고파\n",
      "Output: 얼른 모아야할 이유가 생겼네요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict('배고파')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "212bdbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오늘 놀러갈거야\n",
      "Output: 이별은 언제나 좋죠 .\n"
     ]
    }
   ],
   "source": [
    "output = predict('오늘 놀러갈거야')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fd6f0313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 힘들어\n",
      "Output: 저는 위로해드리는 로봇이에요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict('힘들어')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53613f26",
   "metadata": {},
   "source": [
    "회고\n",
    "\n",
    "트랜스포머 모델의 인코더와 디코더 구조를 알고 모델을 만드니 과정이 조금은 더 잘 이해가 되었다.\n",
    "이전에 자연어처리에서 배웠던 문장 평균 길이 구하기 위해 사분위로 나타내는 것과 데이터 표준화 등이 사용되어서 복습이 되었다.\n",
    "\n",
    "첫번째로 변경한 파라미터는 max_length이다.\n",
    "max_length를 설정할 때 길이를 길게 해서 모든 데이터를 살리는 대신 패딩이 많이 들어가는게 나을지, 길이를 짧게해서 일부 데이터는 제외시키되 패딩을\n",
    "적게 넣는 것이 좋을지 고민이 되었는데 데이터의 토큰 길이가 짧다보니 이럴 경우에는 후자가 더 좋다고 했고, 실제로 결과도 accuracy를 봤을 때 더 높았다.\n",
    "\n",
    "두번째로 변경한 파라미터는 dropout이다.\n",
    "dropout값을 노드 설정값인 0.1에서 0.05로 낮추었는데 loss 값이 더 증가하였다.\n",
    "추가적인 실험을 통해 최적화가 더 필요할 것 같다.\n",
    "\n",
    "마지막으로 알게된 것은 챗봇 모델에서 accuracy보다는 loss 값을 확인하는 것이 더 의미있다고 하였는데 구체적인 설명은 이해를 못했다..\n",
    "\n",
    "여유롭게 학습해서 좋았다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
