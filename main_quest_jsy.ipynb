{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6526e068",
   "metadata": {},
   "source": [
    "GPT 모델 만들기\n",
    "[ 평가 기준 ] 1. 트랜스포머와 비교해 변경한 부분 적기(블럭 단위) -> 코드블럭에 변경 사항을 주석으로 표시\n",
    "\n",
    "기존 transformer에서 변경된 부분"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71bf412",
   "metadata": {},
   "source": [
    "1. 입력값이 변경됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc7d2ba",
   "metadata": {},
   "source": [
    "2. Positional Encoding -> embedding 으로 변경됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7241b43",
   "metadata": {},
   "source": [
    "3. 인코더 삭제됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1941b4b",
   "metadata": {},
   "source": [
    "4. 디코더에서 인코더-디코더 멀티헤드 어텐션 삭제됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c140c4df",
   "metadata": {},
   "source": [
    "5. 인코더, 디코더의 Nx 값 = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a34125c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ba13a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bca65c29",
   "metadata": {},
   "source": [
    "# 0. 버전확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44c5835c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509ac370",
   "metadata": {},
   "source": [
    "# Step 1. 데이터 수집하기\n",
    "### 한국어 챗봇 데이터는 송영숙님이 공개한 챗봇 데이터를 사용합니다.\n",
    "\n",
    "Cloud shell에서 아래 명령어를 입력해 주세요.\n",
    "\n",
    "$ mkdir -p ~/aiffel/transformer_chatbot/data/\n",
    "$ ln -s ~/data/* ~/aiffel/transformer_chatbot/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8800c961",
   "metadata": {},
   "source": [
    "# Step 2. 데이터 전처리하기\n",
    "### 영어 데이터와는 전혀 다른 데이터인 만큼 영어 데이터에 사용했던 전처리와 일부 동일한 전처리도 필요하겠지만 전체적으로는 다른 전처리를 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d48e983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "800ae494",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.expanduser(\"~/aiffel/transformer_chatbot/data/ChatbotData .csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5ac5f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 개수: 11823\n"
     ]
    }
   ],
   "source": [
    "num_samples = len(data)\n",
    "print(\"샘플 개수:\", num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e0adcfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n",
    "# A열의 2, 3행이 \"여행은 언제나 좋죠.\" 로 중복값인 것을 확인함. 각 열의 중복값과 누락값을 확인하고자함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8c0c13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q 열의 누락값 개수: 0\n",
      "A 열의 누락값 개수: 0\n"
     ]
    }
   ],
   "source": [
    "# Q열과 A열 각각의 누락값 개수 확인\n",
    "q_missing = data['Q'].isnull().sum()\n",
    "a_missing = data['A'].isnull().sum()\n",
    "\n",
    "print(\"Q 열의 누락값 개수:\", q_missing)\n",
    "print(\"A 열의 누락값 개수:\", a_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8453ff3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q 열의 중복값 개수: 161\n",
      "A 열의 중복값 개수: 4044\n"
     ]
    }
   ],
   "source": [
    "# Q열과 A열 각각의 중복값 개수 확인\n",
    "q_duplicates = data['Q'].duplicated().sum()\n",
    "a_duplicates = data['A'].duplicated().sum()\n",
    "\n",
    "print(\"Q 열의 중복값 개수:\", q_duplicates)\n",
    "print(\"A 열의 중복값 개수:\", a_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50e773e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복값을 갖는 Q 열 데이터:\n",
      "                             Q                        A  label\n",
      "152    결혼이나 하지 왜 자꾸 나한테 화 내냐구!                   힘들겠네요.      0\n",
      "189             고백하고 후회하면 어떡하지  후회는 후회를 낳을뿐이에요. 용기 내세요.      0\n",
      "195                 고양이 키우고 싶어             자신을 먼저 키우세요.      0\n",
      "196                 고양이 키우고 싶어             가족들과 상의해보세요.      0\n",
      "226          공부는 내 체질이 아닌 것 같아                확신이 없나봐요.      0\n",
      "...                        ...                      ...    ...\n",
      "11658                  첫사랑 생각나           지금의 사랑에 충실하세요.      2\n",
      "11731    커플여행이 나을까 그냥 우리끼리 갈까?         저는 둘이 가는 걸 좋아해요.      2\n",
      "11732    커플여행이 나을까 그냥 우리끼리 갈까?          저는 둘이 가는 게 좋아요.      2\n",
      "11818           훔쳐보는 것도 눈치 보임.       티가 나니까 눈치가 보이는 거죠!      2\n",
      "11819           훔쳐보는 것도 눈치 보임.            훔쳐보는 거 티나나봐요.      2\n",
      "\n",
      "[317 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# 중복값을 갖는 Q열 데이터 확인\n",
    "duplicate_q_data = data[data['Q'].duplicated(keep=False)]\n",
    "\n",
    "print(\"중복값을 갖는 Q 열 데이터:\")\n",
    "print(duplicate_q_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5d02c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q 열과 A 열이 동시에 중복값을 갖는 데이터 개수: 146\n",
      "중복된 Q와 A 열 데이터:\n",
      "                            Q                        A  label\n",
      "152   결혼이나 하지 왜 자꾸 나한테 화 내냐구!                   힘들겠네요.      0\n",
      "189            고백하고 후회하면 어떡하지  후회는 후회를 낳을뿐이에요. 용기 내세요.      0\n",
      "226         공부는 내 체질이 아닌 것 같아                확신이 없나봐요.      0\n",
      "377                  기숙사 괜찮을까         혼자 사는 것보다 불편하겠죠.      0\n",
      "592                 나는 좋은데 ….           현실의 벽에 부딪혔나봐요.      0\n",
      "...                       ...                      ...    ...\n",
      "8764                   환승 가능?               환승은 30분 안에      1\n",
      "8780          회사 사람들이 아직도 불편해        회사에는 동료가 있을 뿐이에요.      1\n",
      "8782     회사에는 왜 친구 같은 사람이 없을까      회사는 친구 사귀는 곳이 아니에요.      1\n",
      "8789                    후련하달까              후련하니 다행이에요.      1\n",
      "9541             내일 만나자고 해볼까?         멋지게 데이트 신청 해보세요.      2\n",
      "\n",
      "[146 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Q열과 A열이 동시에 중복값을 갖는 데이터 확인\n",
    "duplicate_qa_data = data[data.duplicated(subset=['Q', 'A'], keep=False)]\n",
    "\n",
    "# 중복값의 개수 확인\n",
    "num_duplicates = duplicate_qa_data.shape[0]\n",
    "\n",
    "print(\"Q 열과 A 열이 동시에 중복값을 갖는 데이터 개수:\", num_duplicates)\n",
    "print(\"중복된 Q와 A 열 데이터:\")\n",
    "print(duplicate_qa_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fffbb9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152번째 데이터와 중복값을 갖는 데이터의 인덱스: [152, 5527]\n"
     ]
    }
   ],
   "source": [
    "# 152번째 데이터의 Q와 A 값\n",
    "target_q = data.loc[152, 'Q']\n",
    "target_a = data.loc[152, 'A']\n",
    "\n",
    "# 152번째 데이터와 같은 Q와 A 값을 갖는 데이터의 인덱스 찾기\n",
    "duplicate_indices = data[(data['Q'] == target_q) & (data['A'] == target_a)].index.tolist()\n",
    "\n",
    "print(\"152번째 데이터와 중복값을 갖는 데이터의 인덱스:\", duplicate_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0f576d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q        결혼이나 하지 왜 자꾸 나한테 화 내냐구!\n",
      "A                         힘들겠네요.\n",
      "label                          1\n",
      "Name: 5527, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 5527번 데이터 출력\n",
    "print(data.loc[5527])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "879ad6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Q            A  label\n",
      "0           12시 땡!   하루가 또 가네요.      0\n",
      "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
      "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
      "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
      "4          PPL 심하네   눈살이 찌푸려지죠.      0\n"
     ]
    }
   ],
   "source": [
    "# Q와 A 열이 동시에 같은 데이터를 하나만 남기고 삭제\n",
    "data = data.drop_duplicates(subset=['Q', 'A'], keep='first').reset_index(drop=True)\n",
    "\n",
    "# 결과 확인\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cf819e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 개수: 11750\n"
     ]
    }
   ],
   "source": [
    "num_samples = len(data)\n",
    "print(\"샘플 개수:\", num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bef695f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Q       Q_filtered            A    A_filtered\n",
      "0           12시 땡!          12시 땡 !   하루가 또 가네요.   하루가 또 가네요 .\n",
      "1      1지망 학교 떨어졌어      1지망 학교 떨어졌어    위로해 드립니다.    위로해 드립니다 .\n",
      "2     3박4일 놀러가고 싶다     3박4일 놀러가고 싶다  여행은 언제나 좋죠.  여행은 언제나 좋죠 .\n",
      "3  3박4일 정도 놀러가고 싶다  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.  여행은 언제나 좋죠 .\n",
      "4          PPL 심하네          PPL 심하네   눈살이 찌푸려지죠.   눈살이 찌푸려지죠 .\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 한글 불용어 목록\n",
    "stopwords = [\n",
    "    \"이\", \"그\", \"저\", \"가\", \"을\", \"를\", \"에\", \"의\", \"와\", \"과\", \"들\"\n",
    "]\n",
    "\n",
    "def preprocess_korean_text(data):\n",
    "    processed_texts = []\n",
    "    \n",
    "    for sentence in data:\n",
    "        # 구두점 처리\n",
    "        sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "        \n",
    "        # 중복 공백 제거\n",
    "        sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "        \n",
    "        # 양쪽 공백 제거\n",
    "        sentence = sentence.strip()\n",
    "        \n",
    "        processed_texts.append(sentence)\n",
    "    \n",
    "    return processed_texts\n",
    "\n",
    "def remove_stopwords(data, stopwords):\n",
    "    filtered_texts = []\n",
    "    \n",
    "    for sentence in data:\n",
    "        # 텍스트를 공백으로 분리하여 단어 리스트 생성\n",
    "        words = sentence.split()\n",
    "        \n",
    "        # 불용어가 아닌 단어만 필터링\n",
    "        filtered_words = [word for word in words if word not in stopwords]\n",
    "        \n",
    "        # 필터링된 단어를 다시 문자열로 결합\n",
    "        filtered_texts.append(' '.join(filtered_words))\n",
    "    \n",
    "    return filtered_texts\n",
    "\n",
    "\n",
    "# Q열과 A열에 각각 전처리 및 불용어 제거 적용\n",
    "data['Q_processed'] = preprocess_korean_text(data['Q'])\n",
    "data['A_processed'] = preprocess_korean_text(data['A'])\n",
    "\n",
    "data['Q_filtered'] = remove_stopwords(data['Q_processed'], stopwords)\n",
    "data['A_filtered'] = remove_stopwords(data['A_processed'], stopwords)\n",
    "\n",
    "# 결과 확인\n",
    "print(data[['Q', 'Q_filtered', 'A', 'A_filtered']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f90d99f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_filtered 열의 개수: 11750\n",
      "A_filtered 열의 개수: 11750\n"
     ]
    }
   ],
   "source": [
    "# Q_filtered와 A_filtered 열의 개수 확인\n",
    "q_filtered_count = data['Q_filtered'].count()\n",
    "a_filtered_count = data['A_filtered'].count()\n",
    "\n",
    "print(\"Q_filtered 열의 개수:\", q_filtered_count)\n",
    "print(\"A_filtered 열의 개수:\", a_filtered_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd8d99d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label       Q_filtered    A_filtered\n",
      "0      0          12시 땡 !   하루가 또 가네요 .\n",
      "1      0      1지망 학교 떨어졌어    위로해 드립니다 .\n",
      "2      0     3박4일 놀러가고 싶다  여행은 언제나 좋죠 .\n",
      "3      0  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠 .\n",
      "4      0          PPL 심하네   눈살이 찌푸려지죠 .\n"
     ]
    }
   ],
   "source": [
    "# Q열과 A열 삭제\n",
    "data = data.drop(columns=['Q', 'A', 'Q_processed', 'A_processed'])\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8151362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label        questions       answers\n",
      "0      0          12시 땡 !   하루가 또 가네요 .\n",
      "1      0      1지망 학교 떨어졌어    위로해 드립니다 .\n",
      "2      0     3박4일 놀러가고 싶다  여행은 언제나 좋죠 .\n",
      "3      0  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠 .\n",
      "4      0          PPL 심하네   눈살이 찌푸려지죠 .\n"
     ]
    }
   ],
   "source": [
    "# 열 이름 변경\n",
    "data = data.rename(columns={'Q_filtered': 'questions', 'A_filtered': 'answers'})\n",
    "\n",
    "# 결과 확인\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "653fc21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "# Q와 A 결합 (열 이름 변경 반영)\n",
    "combined_data = [f\"{q} <SEP> {a}\" for q, a in zip(data['questions'], data['answers'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea7d85e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                combined\n",
      "0                              12시 땡 ! <SEP> 하루가 또 가네요 .\n",
      "1                           1지망 학교 떨어졌어 <SEP> 위로해 드립니다 .\n",
      "2                        3박4일 놀러가고 싶다 <SEP> 여행은 언제나 좋죠 .\n",
      "3                     3박4일 정도 놀러가고 싶다 <SEP> 여행은 언제나 좋죠 .\n",
      "4                              PPL 심하네 <SEP> 눈살이 찌푸려지죠 .\n",
      "...                                                  ...\n",
      "11745          훔쳐보는 것도 눈치 보임 . <SEP> 티가 나니까 눈치가 보이는 거죠 !\n",
      "11746               훔쳐보는 것도 눈치 보임 . <SEP> 훔쳐보는 거 티나나봐요 .\n",
      "11747                         흑기사 해주는 짝남 . <SEP> 설렜겠어요 .\n",
      "11748  힘든 연애 좋은 연애라는게 무슨 차이일까 ? <SEP> 잘 헤어질 수 있는 사이 여...\n",
      "11749               힘들어서 결혼할까봐 <SEP> 도피성 결혼은 하지 않길 바라요 .\n",
      "\n",
      "[11750 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 리스트를 DataFrame으로 변환\n",
    "df = pd.DataFrame(combined_data, columns=['combined'])\n",
    "\n",
    "# DataFrame 확인\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "035d91b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28)]              0         \n",
      "_________________________________________________________________\n",
      "positional_embedding (Positi (None, 28, 768)           15902208  \n",
      "=================================================================\n",
      "Total params: 15,902,208\n",
      "Trainable params: 15,902,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 토크나이저 설정\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(combined_data)\n",
    "tokenized_data = tokenizer.texts_to_sequences(combined_data)\n",
    "\n",
    "# 패딩 처리 (최대 길이에 맞춰 0으로 채움)\n",
    "padded_data = pad_sequences(tokenized_data, padding='post')\n",
    "\n",
    "# 포지셔널 임베딩 레이어 수정 (배치 차원을 고려하여 브로드캐스트)\n",
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embed_dim, max_len):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        self.token_embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.position_embedding = tf.keras.layers.Embedding(input_dim=max_len, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        seq_len = tf.shape(x)[1]  # 시퀀스 길이\n",
    "        positions = tf.range(start=0, limit=seq_len, delta=1)  # 위치 인덱스 생성\n",
    "        positions = self.position_embedding(positions)  # 위치 임베딩 생성\n",
    "        positions = tf.expand_dims(positions, axis=0)  # 배치 차원 추가\n",
    "        positions = tf.tile(positions, [tf.shape(x)[0], 1, 1])  # 배치 크기에 맞게 타일링\n",
    "\n",
    "        embedded_tokens = self.token_embedding(x)  # 토큰 임베딩 생성\n",
    "        \n",
    "        return embedded_tokens + positions  # 두 임베딩을 더함\n",
    "\n",
    "# GPT 모델을 호출할 때, 디코더가 적절한 3차원 모양으로 입력을 받을 수 있도록 조정합니다.\n",
    "\n",
    "\n",
    "# 임베딩 파라미터 설정\n",
    "embedding_dim = 768  # GPT의 기본 임베딩 차원\n",
    "max_seq_len = len(padded_data[0])  # max_seq_len 설정\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# 포지셔널 임베딩 레이어 생성 및 적용\n",
    "pos_embedding_layer = PositionalEmbedding(vocab_size=vocab_size, embed_dim=embedding_dim, max_len=max_seq_len)\n",
    "inputs = tf.keras.Input(shape=(max_seq_len,))\n",
    "encoded_inputs = pos_embedding_layer(inputs)\n",
    "\n",
    "# 모델 구성\n",
    "model = tf.keras.Model(inputs=inputs, outputs=encoded_inputs)\n",
    "\n",
    "# 모델 구조 확인\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e10e313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output\n",
    "\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b460fd8c",
   "metadata": {},
   "source": [
    "#### 9-7. 머리가 여러 개인 어텐션_멀티 헤드 어텐션 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54645fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)  # Dense를 적용\n",
    "    key = self.key_dense(key)        # Dense를 적용\n",
    "    value = self.value_dense(value)  # Dense를 적용\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)  # 머리 분리\n",
    "    key = self.split_heads(key, batch_size)        # 머리 분리\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00e8d69",
   "metadata": {},
   "source": [
    "#### 9-8. 마스킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ba282d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4890406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d529dc70",
   "metadata": {},
   "source": [
    "#### 9-10. 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "306e7673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "\n",
    "    attention = tf.keras.layers.MultiHeadAttention(\n",
    "        num_heads=num_heads, key_dim=d_model, dropout=dropout, name=\"attention\")(inputs, inputs, attention_mask=look_ahead_mask)\n",
    "    attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + inputs)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, look_ahead_mask], outputs=outputs, name=name)\n",
    "print(\"슝=3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b2ee578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def decoder(vocab_size, num_layers, units, d_model, num_heads, dropout, max_len, name=\"decoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "\n",
    "    embeddings = PositionalEmbedding(vocab_size, d_model, max_len)(inputs)\n",
    "\n",
    "    outputs = embeddings\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(units, d_model, num_heads, dropout, name=f\"decoder_layer_{i}\")(\n",
    "            inputs=[outputs, look_ahead_mask])\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, look_ahead_mask], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29723f40",
   "metadata": {},
   "source": [
    "#### 1. 단어장(Vocabulary) 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be54a93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary 생성 완료\n",
      "START_TOKEN의 번호 : [10428]\n",
      "END_TOKEN의 번호 : [10429]\n",
      "Vocabulary 크기: 10430\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# questions와 answers를 합친 데이터 생성\n",
    "combined_data = data['questions'] + data['answers']\n",
    "\n",
    "# 단어장(Vocabulary) 생성 (questions + answers 대신 combined_data 사용)\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(combined_data, target_vocab_size=2**14)\n",
    "print(\"Vocabulary 생성 완료\")\n",
    "\n",
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "print('START_TOKEN의 번호 :', [tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :', [tokenizer.vocab_size + 1])\n",
    "\n",
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장 크기 설정\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(\"Vocabulary 크기:\", VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13859866",
   "metadata": {},
   "source": [
    "#### 2. 각 단어를 고유한 정수로 인코딩(Integer encoding) & 패딩(Padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca692dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [10101, 2182, 3600]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [2332, 6579, 7, 5474, 108, 1]\n"
     ]
    }
   ],
   "source": [
    "# 각 질문과 답변을 고유한 정수로 인코딩\n",
    "encoded_questions = [tokenizer.encode(sentence) for sentence in data['questions']]\n",
    "encoded_answers = [tokenizer.encode(sentence) for sentence in data['answers']]\n",
    "\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(encoded_questions[21]))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(encoded_answers[21]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "410903f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 샘플: [10101, 2182, 3600, 2332, 6579, 7, 5474, 108, 1]\n"
     ]
    }
   ],
   "source": [
    "# 질문과 답변을 합친 데이터를 고유한 정수로 인코딩\n",
    "encoded_combined = [tokenizer.encode(sentence) for sentence in combined_data]\n",
    "\n",
    "print('정수 인코딩 후의 21번째 샘플: {}'.format(encoded_combined[21]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50fd6a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_data의 최소 길이 : 1\n",
      "combined_data의 최대 길이 : 30\n",
      "combined_data의 평균 길이 : 7.6284255319148935\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# combined_data의 각 문장의 길이를 계산\n",
    "combined_data_len = [len(s.split()) for s in combined_data]\n",
    "\n",
    "# 길이 분포 출력\n",
    "print('combined_data의 최소 길이 : {}'.format(np.min(combined_data_len)))\n",
    "print('combined_data의 최대 길이 : {}'.format(np.max(combined_data_len)))\n",
    "print('combined_data의 평균 길이 : {}'.format(np.mean(combined_data_len)))\n",
    "\n",
    "# combined_data의 길이 분포 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# 박스 플롯(Boxplot)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.boxplot(combined_data_len)\n",
    "plt.title('Combined Data Length Distribution (Boxplot)')\n",
    "\n",
    "# 히스토그램(Histogram)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(combined_data_len, bins=40)\n",
    "plt.title('Combined Data Length Distribution (Histogram)')\n",
    "plt.xlabel('Length of Samples')\n",
    "plt.ylabel('Number of Samples')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a3857a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 15\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eaf04722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "패딩된 combined_data 샘플: [[10428  6949  1779  4777    34  4100    67  6931     1 10429     0     0\n",
      "      0     0     0]\n",
      " [10428 10221    60   894 10204   867  1472  1562  4798     1 10429     0\n",
      "      0     0     0]\n",
      " [10428 10223  1083  4032 10204  3156  8440  1049    36   660   116     1\n",
      "  10429     0     0]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter_combined(combined_data):\n",
    "    tokenized_data = []\n",
    "  \n",
    "    for sentence in combined_data:\n",
    "        # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "        tokenized_sentence = START_TOKEN + tokenizer.encode(sentence) + END_TOKEN\n",
    "\n",
    "        # 최대 길이 15 이하인 경우에만 데이터셋으로 허용\n",
    "        if len(tokenized_sentence) <= MAX_LENGTH:\n",
    "            tokenized_data.append(tokenized_sentence)\n",
    "    \n",
    "    # 최대 길이 15으로 모든 데이터셋을 패딩\n",
    "    tokenized_data = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_data, maxlen=MAX_LENGTH, padding='post')\n",
    "    \n",
    "    return tokenized_data\n",
    "\n",
    "# MAX_LENGTH 설정\n",
    "MAX_LENGTH = 15\n",
    "\n",
    "# combined_data를 사용하여 필터링 및 패딩 처리\n",
    "padded_combined_data = tokenize_and_filter_combined(combined_data)\n",
    "\n",
    "# 처리 결과 확인\n",
    "print(\"패딩된 combined_data 샘플:\", padded_combined_data[:3])  # 예시로 첫 3개 샘플 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54b034aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 10430\n",
      "필터링 후의 샘플 개수: 9322\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print('단어장의 크기 :', VOCAB_SIZE)\n",
    "print('필터링 후의 샘플 개수: {}'.format(len(padded_combined_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72e0532c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# combined_data의 각 문장을 정수 인코딩\n",
    "tokenized_combined_data = [START_TOKEN + tokenizer.encode(sentence) + END_TOKEN for sentence in combined_data]\n",
    "\n",
    "# 리스트를 NumPy 배열로 변환\n",
    "tokenized_combined_data = np.array(tokenized_combined_data, dtype=object)\n",
    "\n",
    "# 정수 인코딩 과정을 수행하면서 샘플의 길이가 15를 넘는 경우 필터링\n",
    "def tokenize_and_filter_combined(tokenized_combined_data):\n",
    "    filtered_data = []\n",
    "  \n",
    "    for tokenized_sentence in tokenized_combined_data:\n",
    "        if len(tokenized_sentence) <= MAX_LENGTH:\n",
    "            filtered_data.append(tokenized_sentence)\n",
    "    \n",
    "    # 리스트를 NumPy 배열로 변환 (패딩 처리를 위해)\n",
    "    filtered_data = np.array(filtered_data, dtype=object)\n",
    "\n",
    "    # 최대 길이 15으로 모든 데이터셋을 패딩\n",
    "    filtered_data = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        filtered_data, maxlen=MAX_LENGTH, padding='post')\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "# 정수 인코딩 및 필터링 수행\n",
    "padded_combined_data = tokenize_and_filter_combined(tokenized_combined_data)\n",
    "\n",
    "# BATCH_SIZE와 BUFFER_SIZE 설정\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 데이터셋 구성\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': padded_combined_data[:, :-1]  # 마지막 토큰을 제외한 시퀀스 (입력)\n",
    "    },\n",
    "    {\n",
    "        'outputs': padded_combined_data[:, 1:]  # 첫 번째 토큰을 제외한 시퀀스 (정답, 예측할 대상)\n",
    "    },\n",
    "))\n",
    "\n",
    "# 데이터셋 준비\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "print(\"슝=3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "223d5e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=TensorSpec(shape=(None, None), dtype=tf.float32, name='inputs'), name='inputs', description=\"created by layer 'inputs'\"), but it was called on an input with incompatible shape (None, None, 256).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=TensorSpec(shape=(None, None), dtype=tf.float32, name='inputs'), name='inputs', description=\"created by layer 'inputs'\"), but it was called on an input with incompatible shape (None, None, 256).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1, None, None) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, None, None), dtype=tf.float32, name='look_ahead_mask'), name='look_ahead_mask', description=\"created by layer 'look_ahead_mask'\"), but it was called on an input with incompatible shape (None, None, None).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1, None, None) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, None, None), dtype=tf.float32, name='look_ahead_mask'), name='look_ahead_mask', description=\"created by layer 'look_ahead_mask'\"), but it was called on an input with incompatible shape (None, None, None).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), name='inputs', description=\"created by layer 'inputs'\"), but it was called on an input with incompatible shape (None, None, 256, 256).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), name='inputs', description=\"created by layer 'inputs'\"), but it was called on an input with incompatible shape (None, None, 256, 256).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1, None, None) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, None, None), dtype=tf.float32, name='look_ahead_mask'), name='look_ahead_mask', description=\"created by layer 'look_ahead_mask'\"), but it was called on an input with incompatible shape (None, None, None).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1, None, None) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, None, None), dtype=tf.float32, name='look_ahead_mask'), name='look_ahead_mask', description=\"created by layer 'look_ahead_mask'\"), but it was called on an input with incompatible shape (None, None, None).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 3 but is rank 4\n\t for 0th input and equation: abc,cde->abde for '{{node decoder/decoder_layer_0/attention/query/einsum/Einsum}} = Einsum[N=2, T=DT_FLOAT, equation=\"abc,cde->abde\"](decoder/positional_embedding_2/add, decoder/decoder_layer_0/attention/query/einsum/Einsum/ReadVariableOp)' with input shapes: [?,?,256,256], [256,8,256].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1879\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1881\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape must be rank 3 but is rank 4\n\t for 0th input and equation: abc,cde->abde for '{{node decoder/decoder_layer_0/attention/query/einsum/Einsum}} = Einsum[N=2, T=DT_FLOAT, equation=\"abc,cde->abde\"](decoder/positional_embedding_2/add, decoder/decoder_layer_0/attention/query/einsum/Einsum/ReadVariableOp)' with input shapes: [?,?,256,256], [256,8,256].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_393/1013383665.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# GPT 모델 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m model = gpt_model(\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_LAYERS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_393/1013383665.py\u001b[0m in \u001b[0;36mgpt_model\u001b[0;34m(vocab_size, num_layers, units, d_model, num_heads, dropout, max_len, name)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# 디코더\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     dec_outputs = decoder(\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    977\u001b[0m                                                 input_list)\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1112\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1113\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1115\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    886\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \"\"\"\n\u001b[0;32m--> 414\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    415\u001b[0m         inputs, training=training, mask=mask)\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \"\"\"\n\u001b[0;32m--> 414\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    415\u001b[0m         inputs, training=training, mask=mask)\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/layers/multi_head_attention.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, query, value, key, attention_mask, return_attention_scores, training)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;31m#   H = `size_per_head`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;31m# `query` = [B, T, N ,H]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;31m# `key` = [B, S, N, H]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/layers/einsum_dense.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m       \u001b[0mret\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/special_math_ops.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(equation, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;34m-\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0mare\u001b[0m \u001b[0minconsistent\u001b[0m \u001b[0;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m   \"\"\"\n\u001b[0;32m--> 751\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_einsum_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/special_math_ops.py\u001b[0m in \u001b[0;36m_einsum_v2\u001b[0;34m(equation, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1178\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mellipsis_label\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0mresolved_equation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresolved_equation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mellipsis_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_linalg_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolved_equation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m     \u001b[0;31m# Send fully specified shapes to opt_einsum, since it cannot handle unknown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_linalg_ops.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(inputs, equation, name)\u001b[0m\n\u001b[1;32m   1089\u001b[0m   \u001b[0m_attr_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m   \u001b[0mequation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"equation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m   1092\u001b[0m         \"Einsum\", inputs=inputs, equation=equation, name=name)\n\u001b[1;32m   1093\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    746\u001b[0m       \u001b[0;31m# Add Op to graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[1;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         compute_device)\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3559\u001b[0m     \u001b[0;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3560\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3561\u001b[0;31m       ret = Operation(\n\u001b[0m\u001b[1;32m   3562\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3563\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2039\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[1;32m   2042\u001b[0m                                 control_input_ops, op_def)\n\u001b[1;32m   2043\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1881\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape must be rank 3 but is rank 4\n\t for 0th input and equation: abc,cde->abde for '{{node decoder/decoder_layer_0/attention/query/einsum/Einsum}} = Einsum[N=2, T=DT_FLOAT, equation=\"abc,cde->abde\"](decoder/positional_embedding_2/add, decoder/decoder_layer_0/attention/query/einsum/Einsum/ReadVariableOp)' with input shapes: [?,?,256,256], [256,8,256]."
     ]
    }
   ],
   "source": [
    "def gpt_model(vocab_size,\n",
    "              num_layers,\n",
    "              units,\n",
    "              d_model,\n",
    "              num_heads,\n",
    "              dropout,\n",
    "              max_len,\n",
    "              name=\"gpt\"):\n",
    "    # 디코더 입력\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # GPT에서는 look_ahead_mask를 사용하여 미래의 단어를 마스킹\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.linalg.band_part(tf.ones((tf.shape(x)[0], tf.shape(x)[1], tf.shape(x)[1])), -1, 0),\n",
    "        name='look_ahead_mask')(inputs)\n",
    "    \n",
    "    # 포지셔널 임베딩 적용\n",
    "    embeddings = PositionalEmbedding(vocab_size, d_model, max_len)(inputs)  # 차원이 맞는 임베딩 적용\n",
    "\n",
    "    # 디코더\n",
    "    dec_outputs = decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        max_len=max_len\n",
    "    )(inputs=[embeddings, look_ahead_mask])\n",
    "\n",
    "    # 출력층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    # GPT 모델은 단일 입력만 사용\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs, name=name)\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "NUM_LAYERS = 12\n",
    "D_MODEL = 256\n",
    "NUM_HEADS = 8\n",
    "UNITS = 512\n",
    "DROPOUT = 0.1\n",
    "MAX_LEN = 15\n",
    "\n",
    "# GPT 모델 생성\n",
    "model = gpt_model(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT,\n",
    "    max_len=MAX_LEN,\n",
    "    name=\"gpt\"\n",
    ")\n",
    "\n",
    "# 모델 구조 출력\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396ff516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87931f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    # y_true를 정리할 필요가 없을 수 있습니다. 필요시 리쉐이핑 가능\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    \n",
    "    # SparseCategoricalCrossentropy 손실 함수 적용\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    # 마스크 생성 및 차원 맞추기 (마스크를 [batch_size, seq_len, 1]로 확장)\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    mask = tf.expand_dims(mask, axis=-1)  # [batch_size, seq_len, 1]\n",
    "    \n",
    "    # 손실 텐서와 마스크를 곱함\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    # 마스킹된 손실의 평균 계산\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "print(\"슝=3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc16d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 된 학습률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b07dea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e09ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8faafd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    # y_pred에서 가장 높은 확률을 가진 단어를 예측 (argmax를 통해 예측 레이블 생성)\n",
    "    y_pred = tf.argmax(y_pred, axis=-1)\n",
    "    \n",
    "    # y_true의 차원과 y_pred의 차원을 일치시키기 위해 y_true의 차원을 reshape\n",
    "    y_true = tf.reshape(y_true, shape=(-1, tf.shape(y_pred)[1]))\n",
    "    \n",
    "    # sparse_categorical_accuracy 함수로 정확도 계산\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7614530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "history = model.fit(dataset, epochs=EPOCHS, verbose=1)\n",
    "\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f5153d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7b7c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  output = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 예측 시작\n",
    "  for i in range(MAX_LENGTH):\n",
    "    predictions = model(inputs=[sentence, output], training=False)\n",
    "\n",
    "    # 현재(마지막) 시점의 예측 단어를 받아온다.\n",
    "    predictions = predictions[:, -1:, :]\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 마지막 시점의 예측 단어를 출력에 연결한다.\n",
    "    # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0)\n",
    "\n",
    "\n",
    "def predict(sentence):\n",
    "  prediction = evaluate(sentence)\n",
    "\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Output: {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9427944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a70fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict('배고파')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee22dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict('오늘 놀러갈거야')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed725c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict('힘들어')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96abf3dc",
   "metadata": {},
   "source": [
    "회고\n",
    "\n",
    "트랜스포머 모델의 인코더와 디코더 구조를 알고 모델을 만드니 과정이 조금은 더 잘 이해가 되었다.\n",
    "이전에 자연어처리에서 배웠던 문장 평균 길이 구하기 위해 사분위로 나타내는 것과 데이터 표준화 등이 사용되어서 복습이 되었다.\n",
    "\n",
    "첫번째로 변경한 파라미터는 max_length이다.\n",
    "max_length를 설정할 때 길이를 길게 해서 모든 데이터를 살리는 대신 패딩이 많이 들어가는게 나을지, 길이를 짧게해서 일부 데이터는 제외시키되 패딩을\n",
    "적게 넣는 것이 좋을지 고민이 되었는데 데이터의 토큰 길이가 짧다보니 이럴 경우에는 후자가 더 좋다고 했고, 실제로 결과도 accuracy를 봤을 때 더 높았다.\n",
    "\n",
    "두번째로 변경한 파라미터는 dropout이다.\n",
    "dropout값을 노드 설정값인 0.1에서 0.05로 낮추었는데 loss 값이 더 증가하였다.\n",
    "추가적인 실험을 통해 최적화가 더 필요할 것 같다.\n",
    "\n",
    "마지막으로 알게된 것은 챗봇 모델에서 accuracy보다는 loss 값을 확인하는 것이 더 의미있다고 하였는데 구체적인 설명은 이해를 못했다..\n",
    "\n",
    "여유롭게 학습해서 좋았다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
